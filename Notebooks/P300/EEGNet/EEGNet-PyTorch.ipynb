{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWritten by, \\nSriram Ravindran, sriram@ucsd.edu\\n\\nOriginal paper - https://arxiv.org/abs/1611.08024\\n\\nPlease reach out to me if you spot an error.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Written by, \n",
    "Sriram Ravindran, sriram@ucsd.edu\n",
    "\n",
    "Original paper - https://arxiv.org/abs/1611.08024\n",
    "\n",
    "Please reach out to me if you spot an error.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here's the description from the paper</p>\n",
    "<img src=\"EEGNet.png\" style=\"width: 700px; float:left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate function returns values of different criteria like accuracy, precision etc. \n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate random data\n",
    "\n",
    "##### Data format:\n",
    "Datatype - float32 (both X and Y) <br>\n",
    "X.shape - (#samples, 1, #timepoints,  #channels) <br>\n",
    "Y.shape - (#samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Training Loss: 3.034483313560486\n",
      "Train: {'acc': 0.5, 'auc': np.float64(0.5480792757523856), 'fmeasure': np.float64(0.15789473684210525)}\n",
      "Validation: {'acc': 0.546875, 'auc': np.float64(0.5096059113300493), 'fmeasure': np.float64(0.14705882352941177)}\n",
      "Test: {'acc': 0.4765625, 'auc': np.float64(0.48229548229548225), 'fmeasure': np.float64(0.10666666666666667)}\n",
      "\n",
      "Epoch 2/5\n",
      "Training Loss: 2.9219780564308167\n",
      "Train: {'acc': 0.484375, 'auc': np.float64(0.47761194029850745), 'fmeasure': np.float64(0.4406779661016949)}\n",
      "Validation: {'acc': 0.5546875, 'auc': np.float64(0.5105911330049261), 'fmeasure': np.float64(0.5210084033613445)}\n",
      "Test: {'acc': 0.53125, 'auc': np.float64(0.5047619047619047), 'fmeasure': np.float64(0.5238095238095238)}\n",
      "\n",
      "Epoch 3/5\n",
      "Training Loss: 2.9577942490577698\n",
      "Train: {'acc': 0.53125, 'auc': np.float64(0.5666748226082701), 'fmeasure': np.float64(0.5384615384615385)}\n",
      "Validation: {'acc': 0.484375, 'auc': np.float64(0.4724137931034483), 'fmeasure': np.float64(0.43103448275862066)}\n",
      "Test: {'acc': 0.4609375, 'auc': np.float64(0.48937728937728936), 'fmeasure': np.float64(0.4390243902439024)}\n",
      "\n",
      "Epoch 4/5\n",
      "Training Loss: 2.9541600346565247\n",
      "Train: {'acc': 0.484375, 'auc': np.float64(0.5184732077318327), 'fmeasure': np.float64(0.5217391304347826)}\n",
      "Validation: {'acc': 0.46875, 'auc': np.float64(0.4509852216748768), 'fmeasure': np.float64(0.49253731343283585)}\n",
      "Test: {'acc': 0.5, 'auc': np.float64(0.5108669108669108), 'fmeasure': np.float64(0.48387096774193544)}\n",
      "\n",
      "Epoch 5/5\n",
      "Training Loss: 2.7519646883010864\n",
      "Train: {'acc': 0.5, 'auc': np.float64(0.5448984585270369), 'fmeasure': np.float64(0.5428571428571428)}\n",
      "Validation: {'acc': 0.4765625, 'auc': np.float64(0.4630541871921182), 'fmeasure': np.float64(0.5179856115107913)}\n",
      "Test: {'acc': 0.515625, 'auc': np.float64(0.5289377289377288), 'fmeasure': np.float64(0.5753424657534246)}\n",
      "\n",
      "Final Test Metrics: [0.4609375, np.float64(0.40122100122100124), np.float64(0.5035971223021583)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "# --------------------------\n",
    "# 1) DEFINE YOUR MODEL\n",
    "# --------------------------\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = 120\n",
    "        \n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 64), padding=0)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16, affine=False)\n",
    "\n",
    "        # Layer 2\n",
    "        self.padding1 = nn.ZeroPad2d((16, 17, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 4, (2, 32))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4, affine=False)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 4)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(4, 4, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(4, affine=False)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # FC Layer (adjust dimensions as needed)\n",
    "        self.fc1 = nn.Linear(4 * 2 * 7, 1)  # => 4 channels * 2 * 7\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = x.permute(0, 3, 1, 2)  # reorder dims (B, 1, H, W) => (B, W, 16, ?)\n",
    "        \n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling2(x)\n",
    "        \n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, 0.25)\n",
    "        x = self.pooling3(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 2) EVALUATE FUNCTION\n",
    "# --------------------------\n",
    "def evaluate(model, X, Y, batch_size=64, device='cpu', metrics=[\"acc\"]):\n",
    "    \"\"\"\n",
    "    Evaluates the model on dataset X with labels Y in chunks of `batch_size`.\n",
    "    Returns a list of metrics in the order specified by `metrics`.\n",
    "    \"\"\"\n",
    "    model.eval()  # Important if you have dropout/batchnorm\n",
    "    predicted_probs = []\n",
    "    \n",
    "    # Forward pass in chunks to avoid OOM errors\n",
    "    n_samples = len(X)\n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        inputs = torch.from_numpy(X[start:end]).float().to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs)            # shape: [batch_size, 1]\n",
    "        predicted_probs.append(preds.cpu().numpy())\n",
    "    \n",
    "    # Concatenate predictions for all batches\n",
    "    predicted_probs = np.concatenate(predicted_probs, axis=0).ravel()  # shape: (n_samples,)\n",
    "    \n",
    "    results = []\n",
    "    for m in metrics:\n",
    "        if m == 'acc':\n",
    "            results.append(accuracy_score(Y, np.round(predicted_probs)))\n",
    "        elif m == 'auc':\n",
    "            results.append(roc_auc_score(Y, predicted_probs))\n",
    "        elif m == 'recall':\n",
    "            results.append(recall_score(Y, np.round(predicted_probs)))\n",
    "        elif m == 'precision':\n",
    "            results.append(precision_score(Y, np.round(predicted_probs)))\n",
    "        elif m == 'fmeasure':\n",
    "            precision = precision_score(Y, np.round(predicted_probs))\n",
    "            recall = recall_score(Y, np.round(predicted_probs))\n",
    "            if precision + recall > 0:\n",
    "                f1 = 2 * precision * recall / (precision + recall)\n",
    "            else:\n",
    "                f1 = 0\n",
    "            results.append(f1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3) TRAINING LOOP\n",
    "# --------------------------\n",
    "def train_loop(model, X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "               criterion, optimizer, device='cpu', epochs=5, batch_size=32):\n",
    "    \"\"\"\n",
    "    A simple training loop with evaluation after each epoch.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()   # set to training mode\n",
    "        running_loss = 0.0\n",
    "        n_samples = len(X_train)\n",
    "        \n",
    "        for start in range(0, n_samples, batch_size):\n",
    "            end = min(start + batch_size, n_samples)\n",
    "            \n",
    "            inputs = torch.from_numpy(X_train[start:end]).float().to(device)\n",
    "            labels = torch.from_numpy(y_train[start:end]).float().to(device)\n",
    "            labels = labels.view(-1, 1)  # make sure shape is [batch_size, 1]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)   # shape: [batch_size, 1]\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Evaluate at the end of each epoch\n",
    "        params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "        train_metrics = evaluate(model, X_train, y_train, batch_size=64, device=device, metrics=params)\n",
    "        val_metrics = evaluate(model, X_val, y_val, batch_size=64, device=device, metrics=params)\n",
    "        test_metrics = evaluate(model, X_test, y_test, batch_size=64, device=device, metrics=params)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print(\"Training Loss:\", running_loss)\n",
    "        print(\"Train:\", dict(zip(params, train_metrics)))\n",
    "        print(\"Validation:\", dict(zip(params, val_metrics)))\n",
    "        print(\"Test:\", dict(zip(params, test_metrics)))\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4) DEMO: SYNTHETIC DATA\n",
    "# --------------------------\n",
    "# We'll mimic your random data approach:\n",
    "X_train = np.random.rand(128, 1, 120, 64).astype('float32')\n",
    "y_train = np.round(np.random.rand(128).astype('float32'))\n",
    "\n",
    "X_val = np.random.rand(128, 1, 120, 64).astype('float32')\n",
    "y_val = np.round(np.random.rand(128).astype('float32'))\n",
    "\n",
    "X_test = np.random.rand(128, 1, 120, 64).astype('float32')\n",
    "y_test = np.round(np.random.rand(128).astype('float32'))\n",
    "\n",
    "# --------------------------\n",
    "# 5) RUN TRAIN & EVAL\n",
    "# --------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = EEGNet()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "train_loop(net, \n",
    "           X_train, y_train, \n",
    "           X_val, y_val, \n",
    "           X_test, y_test, \n",
    "           criterion, optimizer,\n",
    "           device=device,\n",
    "           epochs=5,   # run more for a real scenario\n",
    "           batch_size=32)\n",
    "\n",
    "# Finally, you can do a separate final evaluation if desired:\n",
    "final_test_metrics = evaluate(net, X_test, y_test, batch_size=64, device=device, metrics=[\"acc\",\"auc\",\"fmeasure\"])\n",
    "print(\"\\nFinal Test Metrics:\", final_test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmcv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmpose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_pose_model, inference_top_down_pose_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Example config & checkpoint for a hand pose model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pose_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfigs/hand/td-hm_hrnet_w18_256x256.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Radovan\\anaconda3\\envs\\python_env\\lib\\site-packages\\mmpose\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) OpenMMLab. All rights reserved.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmmcv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmmengine\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m digit_version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mmcv'"
     ]
    }
   ],
   "source": [
    "from mmpose.apis import init_pose_model, inference_top_down_pose_model\n",
    "\n",
    "# Example config & checkpoint for a hand pose model\n",
    "pose_config = 'configs/hand/td-hm_hrnet_w18_256x256.yaml'\n",
    "pose_checkpoint = 'checkpoints/hrnet_w18.pth'\n",
    "\n",
    "# Build the model from a config file and a checkpoint file\n",
    "pose_model = init_pose_model(pose_config, pose_checkpoint, device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
